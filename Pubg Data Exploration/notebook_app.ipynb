{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7402f58c-556e-42a8-bf5d-e94e58ad6186",
   "metadata": {
    "name": "Intro",
    "collapsed": false
   },
   "source": "![Game Data Exploration](https://sfc-gh-jholt.github.io/jgh-images/banner.jpeg)\n"
  },
  {
   "cell_type": "code",
   "id": "ffe610d3-2e5d-4da6-a6ad-cdacc2d8277b",
   "metadata": {
    "language": "python",
    "name": "ImportPackage",
    "collapsed": false
   },
   "outputs": [],
   "source": "import modin.pandas as pd\nimport snowflake.snowpark.modin.plugin\nfrom snowflake.snowpark.context import get_active_session\nimport streamlit as st\nfrom snowflake.snowpark import Session\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom PIL import Image\n\nwarnings.filterwarnings('ignore', category=UserWarning, module=\"snowpark.modin.plugin.utils\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b75beb2-882e-426c-be89-a3f36493df7f",
   "metadata": {
    "language": "python",
    "name": "DefinePandasAPIDF",
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\ndf = pd.read_snowflake(\"gamestats\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f303592a-d4d6-42c3-9f24-68504b346ca8",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Count unique values in each column\nunique_counts = df.nunique()\n\n# Display the unique counts\nprint(\"Unique counts in each column:\")\nprint(unique_counts)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dadab822-92f4-4307-913f-fa176b4a1b3a",
   "metadata": {
    "language": "python",
    "name": "PrintDF",
    "collapsed": false
   },
   "outputs": [],
   "source": "st.dataframe(df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c0f12cb-c3a7-4ff8-aa86-44e089c2b4c3",
   "metadata": {
    "language": "python",
    "name": "ShowColumns",
    "collapsed": false
   },
   "outputs": [],
   "source": "df.columns\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ae98a34-b109-41ec-80ad-5019fd04d4da",
   "metadata": {
    "language": "python",
    "name": "DropNumberColumn",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = df.drop(['NUMBER'], axis=1)  # Adjust based on actual column name\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf3c002b-7ead-46bf-af3f-4bd81a67a36b",
   "metadata": {
    "language": "python",
    "name": "ShowNewDf",
    "collapsed": false
   },
   "outputs": [],
   "source": "st.dataframe(df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "948e8e21-48b5-4dde-a1cb-cd247ac76f51",
   "metadata": {
    "language": "python",
    "name": "PrintShape",
    "collapsed": false
   },
   "outputs": [],
   "source": "print('shape of the dataset=', df.shape)\n\nprint(' \\nThe null count of each column of the dataset are as follows:')\ndf.isnull().sum()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b21b6161-75b4-4dab-93ad-ebefcde0504e",
   "metadata": {
    "language": "python",
    "name": "ViewNulls",
    "collapsed": false
   },
   "outputs": [],
   "source": "# To view the null row from the dataset:\n\ndf[df['WINPLACEPERC'].isnull() == True]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "706dd749-bc79-4f77-8a1c-f3e7495515e8",
   "metadata": {
    "language": "python",
    "name": "DropNulls",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = df.dropna(subset=['WINPLACEPERC'])  # Drop rows with NaN values in 'WINPLACEPERC'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b4f40c3-411a-4a60-b532-fbca55496def",
   "metadata": {
    "language": "python",
    "name": "DefineFeatures",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Function to identify numeric features\ndef numeric_features(dataset):\n    numeric_col = dataset.select_dtypes(include=np.number).columns.tolist()\n    return dataset[numeric_col].head()\n\n# Function to identify categorical features\ndef categorical_features(dataset):\n    categorical_col = dataset.select_dtypes(exclude=np.number).columns.tolist()\n    return dataset[categorical_col].head()\n\n# Function to check the datatypes of all the columns\ndef check_datatypes(dataset):\n    return dataset.dtypes\n\n# Load your DataFrame (assuming 'df' is already loaded from Snowflake or other source)\n# Displaying in Streamlit:\n\n# Title\nst.title(\"Dataframe Overview\")\n\n# Display Numerical Features\nnumeric_columns = numeric_features(df)\nst.subheader(\"Numerical Features\")\nst.dataframe(numeric_columns)  # Streamlit dataframe for better display\n\n# Separator\nst.write(\"====\" * 20)\n\n# Display Categorical Features\ncategorical_columns = categorical_features(df)\nst.subheader(\"Categorical Features\")\nst.dataframe(categorical_columns)\n\n# Separator\nst.write(\"====\" * 20)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e11de291-5bed-4702-bfda-d9d44f8d4cd4",
   "metadata": {
    "language": "python",
    "name": "DefineOutlierColumns",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Function to detect outliers in every feature\ndef detect_outliers(df):\n    cols = list(df)\n    outliers_list = []  # Use a list to store the rows first\n    \n    for column in cols:\n        # Check if the column is numeric\n        if column in df.select_dtypes(include=np.number).columns:\n            q1 = df[column].quantile(0.25)  # First quartile\n            q3 = df[column].quantile(0.75)  # Third quartile\n            iqr = q3 - q1  # Interquartile range\n            fence_low = q1 - (1.5 * iqr)\n            fence_high = q3 + (1.5 * iqr)\n            \n            # Count the number of outliers\n            num_outliers = df.loc[(df[column] < fence_low) | (df[column] > fence_high)].shape[0]\n            \n            # Append the result as a dictionary to the list\n            outliers_list.append({'Feature': column, 'Number of Outliers': num_outliers})\n    \n    # Convert the list of dictionaries into a DataFrame\n    outliers_df = pd.DataFrame(outliers_list)\n    \n    return outliers_df\n\n# Assuming 'df' is already loaded and contains your data\nst.title(\"Outliers Detection\")\n\n# Detect outliers\noutliers_df = detect_outliers(df)\n\n# Display outliers in a Streamlit DataFrame\nst.subheader(\"Outliers per Feature\")\nst.dataframe(outliers_df)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "844126df-1910-47e8-a0bd-64551cff41bb",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "| ![Image 1](https://sfc-gh-jholt.github.io/jgh-images/gif1.gif) | \n\n\n"
  },
  {
   "cell_type": "code",
   "id": "68dddc0f-f4ac-4d67-b9d3-dfe5d593cddf",
   "metadata": {
    "language": "python",
    "name": "KillsDistrobution",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Assuming df['KILLS'] contains the data\n\n# Summary statistics for the number of KILLS\nkills_stats = {\n    'Statistic': ['Average Kills', '50th Percentile (Median)', '75th Percentile', '99th Percentile', 'Maximum Kills'],\n    'Value': [\n        '{:.4f}'.format(df['KILLS'].mean()),\n        df['KILLS'].quantile(0.50),\n        df['KILLS'].quantile(0.75),\n        df['KILLS'].quantile(0.99),\n        df['KILLS'].max()\n    ]\n}\n\n# Convert to a DataFrame\nkills_stats_df = pd.DataFrame(kills_stats)\n\n# Display in Streamlit\nst.title(\"Summary Statistics for KILLS\")\nst.dataframe(kills_stats_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b7e600b-1579-4871-8f8e-10df9f6507d5",
   "metadata": {
    "language": "python",
    "name": "KillsCountPlayers",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.functions import col, when, approx_percentile\n\n\n\n# Assuming session is already established\n# Step 1: Calculate the 99th percentile of the 'KILLS' column\npercentile_99_value = session.table(\"gamestats\").select(approx_percentile(col('KILLS'), 0.99)).collect()[0][0]\n\n# Step 2: Retrieve the original Snowpark DataFrame\nsnowpark_df = session.table(\"gamestats\")\n\n# Step 3: Create a new column 'KILLS_CATEGORIZED' to categorize kills greater than the 99th percentile\ndf_with_kills_categorized = snowpark_df.with_column(\n    'KILLS_CATEGORIZED',\n    when(col('KILLS') > percentile_99_value, '8+').otherwise(col('KILLS').cast('string'))\n)\n\n# Step 4: Convert the Snowpark DataFrame to a Pandas DataFrame for plotting\npandas_df = df_with_kills_categorized.to_pandas()\n\n# Step 5: Plot the data using Seaborn\nplt.figure(figsize=(20, 15))\nsns.countplot(x=pandas_df['KILLS_CATEGORIZED'].astype(str).sort_values())  # Convert to string for plotting\nplt.title('Kill Count', fontsize=15)\nplt.xlabel('KILLS', fontsize=15)\nplt.ylabel('Count', fontsize=13)\n\n# Step 6: Display the plot in Streamlit\nst.pyplot(plt)\n\n# Step 7: Clear the figure to avoid duplication\nplt.clf()\nplt.close()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b413597-1a40-4135-9c6a-3de1334656e1",
   "metadata": {
    "language": "python",
    "name": "KillsStreaks",
    "collapsed": false
   },
   "outputs": [],
   "source": "\naverage_kills = df['KILLSTREAKS'].mean()\nmedian_kills = df['KILLSTREAKS'].quantile(0.50)\nkills_75_percentile = df['KILLSTREAKS'].quantile(0.75)\nkills_99_percentile = df['KILLSTREAKS'].quantile(0.99)\nmax_kills = df['KILLSTREAKS'].max()\n\n# Step 1: Display the statistics using Streamlit's st.write()\nst.write(f'The average person kills {average_kills:.4f} players in a short time.')\nst.write(f'50% of people have {median_kills} kills or less in a short time.')\nst.write(f'75% of people have {kills_75_percentile} kills or less in a short time.')\nst.write(f'99% of people have {kills_99_percentile} kills or less in a short time.')\nst.write(f'While the most kills in a row recorded in the data is {max_kills}.')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee8a46f6-c9ac-4799-8b23-bda688d4955d",
   "metadata": {
    "language": "python",
    "name": "ChartStreak",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Assuming df is already loaded\n\n\n# Step 1: Calculate the 99th percentile for 'KILLSTREAKS'\npercentile_99_value = session.table(\"gamestats\").select(approx_percentile(col('KILLSTREAKS'), 0.99)).collect()[0][0]\n\n# Step 2: Retrieve the original Snowpark DataFrame\nsnowpark_df = session.table(\"gamestats\")\n\n# Step 3: Use SQL-style transformations to categorize 'KILLSTREAKS' above the 99th percentile\ndf_with_killstreaks_categorized = snowpark_df.with_column(\n    'KILLSTREAKS_CATEGORIZED',\n    when(col('KILLSTREAKS') > percentile_99_value, '4+').otherwise(col('KILLSTREAKS').cast('string'))\n)\n\n# Step 4: Convert the Snowpark DataFrame to Pandas for visualization\npandas_df = df_with_killstreaks_categorized.to_pandas()\n\n# Step 5: Plot the data using Seaborn\nplt.figure(figsize=(20, 15))\nsns.countplot(x=pandas_df['KILLSTREAKS_CATEGORIZED'].sort_values())\nplt.title('Kill Count', fontsize=15)\nplt.xlabel('KILLSTREAKS', fontsize=15)\nplt.ylabel('Count', fontsize=13)\n\n# Step 6: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff037f59-4795-4afe-9710-9755c0ee022e",
   "metadata": {
    "language": "python",
    "name": "MatchTypesCount",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Assuming df is a Pandas DataFrame\n# Get the value counts of the 'MATCHTYPE' column\nmatchtype_counts = df['MATCHTYPE'].value_counts().reset_index()\n\n# Rename the columns for better readability\nmatchtype_counts.columns = ['Match Type', 'Count']\n\n# Step 1: Display the table in Streamlit using st.write or st.dataframe\nst.write(\"### Match Type Counts\")\nst.dataframe(matchtype_counts)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7c9dc23-58de-485e-8ecb-c9ee51544a57",
   "metadata": {
    "language": "python",
    "name": "MatchTypeGraph",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Step 1: Set the plot size\nplt.figure(figsize=(20, 15))\n\n# Step 2: Create a countplot for 'MATCHTYPE' with logarithmic scaling on the y-axis\nsns.countplot(x=df['MATCHTYPE'], hue=df['MATCHTYPE'], palette=\"Set2\", legend=False)\n\n# Step 3: Customize the plot\nplt.title('Match Type with Log Scale', fontsize=15)\nplt.xlabel('Match Type', fontsize=15)\nplt.ylabel('Count (log scale)', fontsize=13)\n\n# Step 4: Set the y-axis to logarithmic scale\nplt.yscale('log')\n\n# Step 5: Display the plot in Streamlit\nst.pyplot(plt)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3d5ea63-7c8f-43dd-a086-b1220e3c6dfe",
   "metadata": {
    "language": "python",
    "name": "DamageByNonLethalPlayers",
    "collapsed": false
   },
   "outputs": [],
   "source": "import pandas as pan\n\n\n# Step 1: Load the data from Snowpark and convert it to a Pandas DataFrame\ndata = session.table(\"gamestats\").to_pandas()\n\n# Step 2: Convert all column names to uppercase for consistency\ndata.columns = [col.upper() for col in data.columns]\n\n# Step 3: Keep only those players that didn't kill anyone\ndata = data[data['KILLS'] == 0]\n\n# Step 4: Ensure 'DAMAGEDEALT' is numeric and handle NaNs or non-numeric values\ndata['DAMAGEDEALT'] = pan.to_numeric(data['DAMAGEDEALT'], errors='coerce').fillna(0)\n\n# Step 5: Apply logarithmic transformation to 'DAMAGEDEALT' to reduce skew\ndata['LOG_DAMAGEDEALT'] = np.log1p(data['DAMAGEDEALT'])  # log1p handles log(0) gracefully\n\n# Step 6: Plot the distribution of log-transformed 'DAMAGEDEALT' using histplot\nplt.figure(figsize=(15, 10))\nplt.title('Log-Scaled Damage Dealt by 0 Killers', fontsize=15)\n\n# Use histplot to plot the distribution\nsns.histplot(data['LOG_DAMAGEDEALT'], kde=True, bins=30)\nplt.xlabel('Log Damage Dealt', fontsize=15)\nplt.ylabel('Density', fontsize=13)\n\n# Step 7: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55d454cb-f8bb-4c53-8877-868fa75501bf",
   "metadata": {
    "language": "python",
    "name": "MatchDurationForWinners",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Step 1: Ensure 'WINPLACEPERC' is numeric and handle any missing values\ndata['WINPLACEPERC'] = pan.to_numeric(data['WINPLACEPERC'], errors='coerce')  # Convert to numeric, invalid entries become NaN\n\n\n# Step 2: Keep only the players that won the match (WINPLACEPERC == 1)\ndata = data[data['WINPLACEPERC'] == 1]\n\n# Step 3: Set up the plot\nplt.figure(figsize=(15, 10))\nplt.title('Match Duration for Winners', fontsize=15)\n\n# Step 4: Create the histogram plot for 'MATCHDURATION'\nsns.histplot(data['MATCHDURATION'], kde=False)\n\n# Step 5: Label the axes\nplt.xlabel('Match Duration', fontsize=15)\nplt.ylabel('Density', fontsize=13)\n\n# Step 6: Display the plot in Streamlit\nst.pyplot(plt)\n\n\n# Step 7: Clear the figure to avoid duplication\nplt.clf()\nplt.close()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2a58686-25de-4dfd-9bb6-87e6b8c2bbfa",
   "metadata": {
    "language": "python",
    "name": "StreakOverWins",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 1: Load the data from Snowflake into a Pandas DataFrame\ndf = session.table(\"gamestats\").to_pandas()\n\n# Step 2: Set up the plot size and create a jointplot\nplt.figure(figsize=(15, 10))\nsns.jointplot(x='WINPLACEPERC', y='KILLSTREAKS', data=df, color='b')\n\n# Step 3: Add axis labels\nplt.xlabel('Win Place Percentage', fontsize=15)\nplt.ylabel('Kill Streaks', fontsize=13)\n\n# Step 4: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52b33d5c-83d7-47f6-a41d-839ee169670e",
   "metadata": {
    "language": "python",
    "name": "DamagevsWins",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Step 1: Set up the jointplot\njoint_plot = sns.jointplot(x='WINPLACEPERC', y='DAMAGEDEALT', data=df, kind='scatter', color='b')\n\n# Step 2: Customize plot with labels\njoint_plot.set_axis_labels('Win Place Percentage', 'Damage Dealt', fontsize=15)\n\n# Step 3: Add a title using suptitle (since jointplot doesn't work well with plt.title)\nplt.suptitle('Win Place vs Damage Dealt', y=1.03, fontsize=16)\n\n# Step 4: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b083f010-67b9-4d9c-b569-49cfa8e4a425",
   "metadata": {
    "language": "python",
    "name": "OwnTeamLethal",
    "collapsed": false
   },
   "outputs": [],
   "source": "print('The average person kills {:.4f} players on their own team'.format(df['TEAMKILLS'].mean()))\nprint('50% of people have killed ',df['TEAMKILLS'].quantile(0.50),' team players')\nprint('75% of people have killed ',df['TEAMKILLS'].quantile(0.75),' team players')\nprint('99% of people have killed ',df['TEAMKILLS'].quantile(0.99),' team players')\nprint('while the most kills recorded in the data is', df['TEAMKILLS'].max())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "859bf245-090b-4991-a76b-e6be39b9c4ef",
   "metadata": {
    "language": "python",
    "name": "TeamLethalOverWins",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 1: Load the data from Snowflake into a Pandas DataFrame\ndf = session.table(\"gamestats\").to_pandas()\n\n# Step 2: Set up the plot size and create a jointplot\nplt.figure(figsize=(15, 10))\nsns.jointplot(x='WINPLACEPERC', y='TEAMKILLS', data=df, color='b')\n\n# Step 3: Add axis labels\nplt.xlabel('Win Place Percentage', fontsize=15)\nplt.ylabel('Team Kills', fontsize=13)\n\n# Step 4: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "540c6b85-0314-476e-b57b-a9988ee82e21",
   "metadata": {
    "language": "python",
    "name": "DistanceTravelled",
    "collapsed": false
   },
   "outputs": [],
   "source": "data = df[['WINPLACEPERC']].copy()\ndata['TOTALDISTANCE'] = df['WALKDISTANCE'] + df['RIDEDISTANCE'] + df['SWIMDISTANCE']\n\n# Summary statistics for the total distance travelled\nprint('The average person travelled {:.2f} m'.format(data['TOTALDISTANCE'].mean()))\nprint('25% of people have travelled {:.2f} m or less'.format(data['TOTALDISTANCE'].quantile(0.25)))\nprint('50% of people have travelled {:.2f} m or less'.format(data['TOTALDISTANCE'].quantile(0.50)))\nprint('75% of people have travelled {:.2f} m or less'.format(data['TOTALDISTANCE'].quantile(0.75)))\nprint('99% of people have travelled {:.2f} m or less'.format(data['TOTALDISTANCE'].quantile(0.99)))\nprint('The longest distance travelled in the data is {:.2f} m'.format(data['TOTALDISTANCE'].max()))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dd923ca-5525-4a7d-ad4c-41c288545245",
   "metadata": {
    "language": "python",
    "name": "DistanceOverWins",
    "collapsed": false
   },
   "outputs": [],
   "source": "data = df[['WINPLACEPERC']].copy()\ndata['TOTALDISTANCE'] = df['WALKDISTANCE'] + df['RIDEDISTANCE'] + df['SWIMDISTANCE']\n\n\n# Step 2: Set up the plot size and create a jointplot\nplt.figure(figsize=(15, 10))\nsns.jointplot(x='WINPLACEPERC', y='TOTALDISTANCE', data=data, color='b')\n\n# Step 3: Add axis labels\nplt.xlabel('Win Place Percentage', fontsize=15)\nplt.ylabel('Team Kills', fontsize=13)\n\n# Step 4: Display the plot in Streamlit\nst.pyplot(plt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "713acef6-4539-4484-bf29-0accf9bb7001",
   "metadata": {
    "language": "python",
    "name": "HealingInsights",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Summary statistics for the number of healing items used\nprint('The average person uses {:.2f} healing items'.format(df['HEALS'].mean()))\nprint('50% of people used {:.2f} healing items'.format(df['HEALS'].quantile(0.50)))\nprint('75% of people used {:.2f} healing items or less'.format(df['HEALS'].quantile(0.75)))\nprint('99% of people used {:.2f} healing items or less'.format(df['HEALS'].quantile(0.99)))\nprint('The doctor of the data used {:.2f} healing items'.format(df['HEALS'].max()))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "397effd6-5ff2-40dd-8f95-f61d0f089813",
   "metadata": {
    "language": "python",
    "name": "BoostsInsights",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Summary statistics for the number of boosting items used\nprint('The average person uses {:.2f} boosting items'.format(df['BOOSTS'].mean()))\nprint('50% of people used {:.2f} boosting items'.format(df['BOOSTS'].quantile(0.50)))\nprint('75% of people used {:.2f} boosting items or less'.format(df['BOOSTS'].quantile(0.75)))\nprint('99% of people used {:.2f} boosting items or less'.format(df['BOOSTS'].quantile(0.99)))\nprint('The addict of the data used {:.2f} boosting items'.format(df['BOOSTS'].max()))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2982c64a-112a-41d9-aa56-6e0d84d0000c",
   "metadata": {
    "language": "python",
    "name": "HealsandBoostsWins",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Assume df is your DataFrame\ndata = df.copy()\n\n# Filter out the top 1% to remove outliers\ndata = data[data['HEALS'] < data['HEALS'].quantile(0.99)]\ndata = data[data['BOOSTS'] < data['BOOSTS'].quantile(0.99)]\n\n# Drop missing values\ndata = data.dropna(subset=['HEALS', 'BOOSTS', 'WINPLACEPERC'])\n\n# Check if the DataFrame is empty\nif data.empty:\n    st.write(\"No data to display after filtering.\")\nelse:\n    # Create the figure and axes\n    f, ax1 = plt.subplots(figsize=(20, 10))\n\n    # Plot the data\n    sns.pointplot(x='HEALS', y='WINPLACEPERC', data=data, color='red', alpha=1.0, ax=ax1)\n    sns.pointplot(x='BOOSTS', y='WINPLACEPERC', data=data, color='blue', alpha=0.8, ax=ax1)\n\n    # Add text labels\n    plt.text(4, 0.6, 'HEALS', color='red', fontsize=17, style='italic')\n    plt.text(4, 0.55, 'BOOSTS', color='blue', fontsize=17, style='italic')\n\n    # Set labels and title\n    plt.xlabel('Number of heal/boost items', fontsize=15, color='blue')\n    plt.ylabel('Win Percentage', fontsize=15, color='blue')\n    plt.title('HEALS vs BOOSTS', fontsize=20, color='blue')\n\n    # Show grid\n    plt.grid()\n\n    # Display the plot in Streamlit\n    st.pyplot(f)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8089125a-42d1-41da-9df6-a81044d2abcc",
   "metadata": {
    "language": "python",
    "name": "FeatureCorrelation",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Select only numeric columns for correlation\nnumeric_df = df.select_dtypes(include=[np.number])\n    \n# Compute the correlation matrix\ncorr_matrix = numeric_df.corr()\n    \n# Display the correlation matrix\nst.subheader('Correlation Matrix')\nst.dataframe(corr_matrix)\n    \n# Plot the heatmap\nst.subheader('Correlation Heatmap')\nfig, ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(corr_matrix, annot=True, linewidths=.5, fmt='.2f', ax=ax)\n    \n# Display the matplotlib figure in Streamlit\nst.pyplot(fig)\n\n\n# Step 7: Clear the figure to avoid duplication\nplt.clf()\nplt.close()",
   "execution_count": null
  }
 ]
}